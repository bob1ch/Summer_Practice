\documentclass[../document.tex]{subfiles}

\begin{document}
    \subsection{Индивидуальное задание практики}
    \par В качестве индивидуального задания практики было поручено исследовать возможность распознавания медведей при помощи методов машинного обучения.
    \par Само по себе распознавание медведей является актуальной и интересной задачей, так как разработанные решения можно использовать для:
    \begin{itemize}
    	\item Исследование поведения медведей
    	\item Обеспечение безопасного проведения работ в областях, которые расположены в местах обитания медведей
    	\item Исследование миграции медведей
    	\item Наблюдение за медведями в местах их содержания(вольеры, заповедники и т.д.)
    \end{itemize}
    
    \subsection{Выбор моделей}
	    \par Для выполнения задания в первую очередь требовалось выбрать рассматриваемые модели. К моделям были применены следующие требования, а именно:
	    \begin{itemize}
	    	\item Быстродействие
	    	\item Точность
	    	\item Возможность решать задачи классификации изображений или детекции
	    \end{itemize}
	    \par В частном случае задача детекции была превращена в задачу классификации, так как если модель смогла на изображении найти объект с нужным классом, то в качестве ответа получали только метку класса, а именно есть медведь на изображении или он отсутствует.
	    \par Были выбраны следующие модели:
	    \begin{itemize}
	    	\item YOLO
	    	\item RT-DETR
	    	\item Faster R-CNN
	    \end{itemize}
	    \par Для всех моделей были использованы веса, которые обучили на датасете Common Objects in Context (COCO).
    
    \subsection{YOLO}
	    \par Когда в задаче говорится о детекции объектов, то в первую очередь для решения этой задачи в голову приходит архитектура YOLO.
	    \par YOLO (You Only Look Once), популярная модель обнаружения объектов и сегментации изображений, была разработана Джозефом Редмоном и Али Фархади в Университете Вашингтона. Появившись в 2015 году, YOLO быстро завоевала популярность благодаря своей высокой скорости и точности.
	    \par На сегодняшний день существует не менее 10 версий описываемой архитектуры.
	    \par Алгоритм YOLO, был первой попыткой сделать возможной детекцию объектов в реальном времени. В рамках алгоритма YOLO исходное изображение сначала разбивается на сетку из $N×N$ ячеек. Если центр объекта попадает внутрь координат ячейки, то эта ячейка считается ответственной за определение параметров местонахождения объекта. Каждая ячейка описывает несколько вариантов местоположения ограничивающих рамок для одного и того же объекта. Каждый из этих вариантов характеризуется пятью значениями — координатами центра ограничивающей рамки, его шириной и высотой, а также степени уверенности в том, что ограничивающая рамка содержит в себе объект. Также необходимо для каждой пары класса объектов и ячейки определить вероятность того, что ячейка содержит в себе объект этого класса. Таким образом, последний слой сети, принимающий конечное решение об ограничивающих рамках и классификации объектов работает с тензором размерности $N×N×(5B+C)$, где $B$ — количество предсказываемых ограничивающих рамок для ячейки, $C$ — количество классов объектов, определённых изначально.
	    
	    \begin{figure}[H]
	    	\centering
	    	\includegraphics[scale=0.5]{YOLO_alg.png}
	    	\caption{Алгоритм YOLO}
	    \end{figure}
	    \begin{figure}[H]
	    	\centering
	    	\includegraphics[scale=0.5]{YOLO_arch.png}
	    	\caption{Архитектура YOLO}
		\end{figure}
	
	\subsection{RT-DETR}
		\par Следующей исследуемой архитектурой стали визуальные трансформеры. К использованию Real-Time Detection Transformer(RT-DETR) подтолкнула статья на arxiv "DETRs Beat YOLOs on Real-time Object Detection" и готовая реализация в бибилотеке ultralytics.
		\par По мению авторов статьи, использование подавления немаксимумов (Non-Maximum Suppression, NMS), который является важных шагом в детекции YOLO, негативно сказывается на производительности и точности модели. В свою очередь авторы отказываюстя от NMS и описывают свою архитектуру следующим образом.
		\par Мы передаем признаки из последних трех слоев бэкбона в кодер. Эффективный гибридный кодер преобразует многомасштабные признаки в последовательность признаков изображения посредством внутримасштабного взаимодействия признаков основанного на внимании (Attention based Intra-scale Feature Interaction, AIFI) и слияния межмасштабных признаков на основе CNN (CNN-based Cross-scale Feature Fusion, CCFF). Затем выбор запроса с минимальной неопределенностью выбирает фиксированное количество признаков кодера, которые будут служить начальными объектными запросами для декодера. Наконец, декодер со вспомогательными головами прогнозирования итеративно оптимизирует объектные запросы для генерации категорий и блоков.
		\begin{figure}[H]
			\centering
			\includegraphics[scale=0.5]{RT-DETR_arch.png}
			\caption{Представление RT-DETR}
		\end{figure}
		
		\par Также авторы сделали бенчмарк с датасетом MS COCO и сравнили свою архитектуру с другими моделями детекции в реальном времени и показали, что их архитектура достигает SOTA
		\begin{figure}[H]
			\centering
			\includegraphics[scale=0.5]{RT-DETR_test.png}
			\caption{Сравнение RT-DETR с другими моделями детекции}
		\end{figure}
	
	\subsection{Faster R-CNN}
		\par Заключительной рассматриваемой архитектурой стали Сверточные сети, основанные на регионах
 или же Region-based CNN (R-CNN), а в частности их модификация Faster R-CNN.
 		\par Эта архитектура была выбрана для рассмотрения как одна из классических архитектур, которая решает задачу детекции. В её основе лежит алгоритм выборочного поиска (Selective Search). Данный алгоритм получает на вход изображение, а на выходе выдает массив прямоугольников, в которых возможно находится объект. И идея такова, что в первую очередь будет проведен выборочный поиск, при помощи которого мы получим кропы изображений, а уже эти кропы мы помещаем в классификатор.
 		\par В дальнейшем эту идею развили, потому что нам не нравилось, что для каждой гипотезы из выборочного поиска мы выполняли классификацию, поэтмоу решили сперва выполнить свертку и получить карту признаков(Feature Map), затем на исходном изображении получить гипотезы и их спроецировать на карту признаков. Этот алгоритм назвали Fast R-CNN.
 		\par Заключительной идее в R-CNN стало следующее: выборочный поиск решили заменить на нейронную сеть. И теперь поиск границ объектов это тоже обучаемый алгоритм.
 		
 		\begin{figure}[H]
 			\centering
 			\includegraphics[scale=0.5]{R-CNN_alg.png}
 			\caption{Принцип работы Faster R-CNN}
 		\end{figure}
 	
 	\subsection{Исследование моделей}
 		\par Для исследования моделей был собран небольшой тестовый датасет из 71 изображения. 51 изображение содержало медведей, 20 изображений медведей не содержали. Изображения подбирались с учетом специфики задания, а именно подбирались изображения из дикой природы, полученные при помощи фотоловушек или съемки издалека, то есть художественные снимки заведомо не подходили, так как имели высокое качество, что в свою очередь не соответствовало специфике задания.
 		\begin{figure}[H]
 			\centering
 			\includegraphics{bear3.jpg}
 			\caption{Пример изображения, которое содержит медведя}
 		\end{figure}
 		\begin{figure}[H]
 			\centering
 			\includegraphics{8.jpg}
 			\caption{Пример изображения, которое медведя не содержит}
 		\end{figure}
 		\par Для выполнения работы были использованы следующие библиотеки:
 		\begin{itemize}
 			\item ultralytics
 			\item torchvision
 			\item matplotlib
 			\item sklearn
 		\end{itemize}
 		\par Метрикой качества модели была выбрана accuracy, также были построены матрицы ошибок и ROC кривая.
 		\par Вычисление метрики, посмотрение матриц ошибок и ROC кривой было выполнено в виде функций, в которые передавались истинные метки и метки предказанные моделями. В функцию для построения ROC кривой вместо предсказанных меток передавалась уверенность модели в ответе.
 		
 		\noindent Вычисление точности:
 		\begin{minted}{python}
def print_accuracy(y_pred_dict, y_true, save = False, file_name = 'accuracy.txt'):
    file = open(file_name, 'w') if save else None
	
    for model, y_pred in y_pred_dict.items():
        print(f'{model} acc: {(y_pred == y_true).mean()}', file=file)
	
	if save:
	    print(f'accuracy metrics saved in {file_name}')
	    file.close()
	    \caption{Вычисление точности}
 		\end{minted}
 		\noindent Построение матрицы ошибок:
 		\begin{minted}{python}
def plot_conf_mat(y_pred_dict, y_true, rows_cols: tuple[int] | None = None, figsize: tuple[int] | None = None, save = False, file_name = 'ConfMat_plot.png'):
	if not rows_cols:
		rows, cols = factor(len(y_pred_dict)) #определяем кол-во строк и столбцов при помощи разложения на множители
	rows, cols = rows_cols
	fig, axs = plt.subplots(rows, cols, figsize=figsize)
	counter = 0
		for i in range(rows):
			for j in range(cols):
			model, y_pred = list(y_pred_dict.items())[counter]
			cm = confusion_matrix(y_true, y_pred)
			axs[i][j].set_title(model)
			ConfusionMatrixDisplay(cm).plot(ax=axs[i][j])
			counter +=1
	plt.tight_layout()
	if save:
		plt.savefig(file_name)
 		\end{minted}
 		\noindent Построение ROC кривой
 		\begin{minted}{python}
def plot_roc_curve(y_conf_dict, y_true, save = False, file_name = 'roc_curve.png'):
	fig, ax = plt.subplots(1, 1, figsize=(10, 10))
	
	for name, y_conf in y_conf_dict.items():
		fpr, tpr, thresholds = metrics.roc_curve(y_true, y_conf)
		roc_auc = metrics.auc(fpr, tpr)
		metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc, estimator_name=name).plot(ax=ax)
	
	ax.plot((0, 1), (0, 1), 
		label="Chance level (AUC = 0.5)",
		color="k",
		linestyle="--",)
	ax.legend()
	ax.set_title("Receiver Operating Characteristic (ROC) curves")
	ax.grid(linestyle="--")
	plt.tight_layout()
	
	if save:
		plt.savefig(file_name)
 		\end{minted}
 		\par Результаты исследования моделей представлены ниже.
 		\begin{figure}[H]
 			\centering
 			\includegraphics[scale=0.35]{ConfMat_plot.png}
 			\caption{Матрица ошибок для моделей YOLO и RT-DETR}
 		\end{figure}
 		\begin{figure}[H]
 			\centering
 			\includegraphics[scale=0.4]{RCNN_ConfMat.png}
 			\caption{Матрица ошибок для моделей Faster R-CNN}
 		\end{figure}
 		\begin{figure}[H]
 			\centering
 			\includegraphics[scale=0.4]{roc_curve.png}
 			\caption{ROC кривая для моделей YOLO и RT-DETR}
 		\end{figure}
 		\begin{figure}[H]
 			\centering
 			\includegraphics[scale=0.4]{RCNN_roc_curve.png}
 			\caption{ROC кривая для моделей Faster R-CNN}
 		\end{figure}
 		\par Полученные значения метрики качества:
 		\begin{minted}{bash}
yolov5nu acc: 0.7361111111111112
yolov8n acc: 0.7777777777777778
yolov8s acc: 0.8472222222222222
yolov8m acc: 0.8888888888888888
yolov9t acc: 0.8055555555555556
yolov10n acc: 0.75
yolov10s acc: 0.8611111111111112
yolov10m acc: 0.9027777777777778
yolov8l acc: 0.9166666666666666
yolov8x acc: 0.9444444444444444
yolov9c acc: 0.8611111111111112
yolov9e acc: 0.9861111111111112
yolov10l acc: 0.9305555555555556
yolov10x acc: 0.9027777777777778
rtdetr-l acc: 0.9722222222222222
rtdetr-x acc: 0.9583333333333334
fasterrcnn_resnet50_fpn acc: 0.5416666666666666
fasterrcnn_resnet50_fpn_v2 acc: 0.5277777777777778
fasterrcnn_mobilenet_v3_large_fpn acc: 0.3472222222222222
fasterrcnn_mobilenet_v3_large_320_fpn acc: 0.4305555555555556
 		\end{minted}
\end{document}
